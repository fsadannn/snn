{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.layers import Embedding, Dense, Input, Flatten, Concatenate, Dropout\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical, plot_model\n",
    "import pydot\n",
    "import keras.optimizers as kop\n",
    "from keras import backend as K\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_map = {}\n",
    "relations_map = {}\n",
    "people_map = {}\n",
    "\n",
    "#tuples = []\n",
    "dictionary = set()\n",
    "\n",
    "max_tuples = 1000000\n",
    "#max_tuples = 1000\n",
    "\n",
    "MODEL_NAME = \"IMDB_ONTO_EMBEDING2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/relations.tsv') as fp:\n",
    "    for i, line in enumerate(fp):\n",
    "        if i >= max_tuples:\n",
    "            break\n",
    "        \n",
    "        title, relation, person = line.lower().strip().split(\"\\t\")\n",
    "        if relation == 'self':\n",
    "            continue\n",
    "        \n",
    "        if title not in movies_map:\n",
    "            movies_map[title] = len(movies_map)\n",
    "            \n",
    "        if relation not in relations_map:\n",
    "            relations_map[relation] = []\n",
    "            relations_map[relation].append((title,person))\n",
    "        else:\n",
    "            relations_map[relation].append((title,person))\n",
    "            \n",
    "        if person not in people_map:\n",
    "            people_map[person] = len(people_map)\n",
    "            \n",
    "        #tuples.append(( movies_map[title], relations_map[relation], people_map[person] ))\n",
    "        \n",
    "        for w in title.split() + relation.split() + person.split():\n",
    "            dictionary.add(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "enties = tuple(['movie','person'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/american-english',encoding = 'utf8') as f:\n",
    "    for i in f:\n",
    "        i = i.strip()\n",
    "        if len(set(i))>1:\n",
    "            dictionary.add(i)\n",
    "with open('../data/cracklib-small',encoding = 'utf8') as f:\n",
    "    for i in f:\n",
    "        i = i.strip()\n",
    "        if len(set(i))>1:\n",
    "            dictionary.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = { w:i for i,w in enumerate(sorted(dictionary)) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumpp = {}\n",
    "dumpp['vocabulary'] = dictionary\n",
    "dumpp['relations'] = {i:(enties[0],enties[1]) for i in relations_map.keys()}\n",
    "dumpp['entities'] = enties\n",
    "json.dump(dumpp,open(MODEL_NAME+'_data.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NNmodels import OntoEmbeding2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parámetros de la red\n",
    "sentence_size = len(dictionary)\n",
    "neurons_per_ent = 10\n",
    "neurons_per_rel = 2*neurons_per_ent\n",
    "# construir la red ontológica\n",
    "# entrada\n",
    "sentence_input = Input(shape=(sentence_size,), name='input')\n",
    "# red\n",
    "onto = OntoEmbeding2(enties,dumpp['relations'])(sentence_input,neurons_per_ent,neurons_per_rel,True)\n",
    "# modelo final\n",
    "model = Model(inputs=sentence_input, outputs=onto)\n",
    "#opt = kop.SGD(lr=0.5,momentum=0.9,decay=0.9,nesterov=True)\n",
    "model.compile(optimizer='RMSprop', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "mm=model_to_dot(model, rankdir='LR').create(prog='dot', format='pdf')\n",
    "with open(MODEL_NAME+'.pdf','wb') as f:\n",
    "    f.write(mm)\n",
    "#SVG(model_to_dot(model, rankdir='LR').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 267178)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "movie (Dense)                   (None, 10)           2671790     input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "person (Dense)                  (None, 10)           2671790     input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "actor (Relation)                (None, 20)           640         movie[0][0]                      \n",
      "                                                                 person[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "actress (Relation)              (None, 20)           640         movie[0][0]                      \n",
      "                                                                 person[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "archive_footage (Relation)      (None, 20)           640         movie[0][0]                      \n",
      "                                                                 person[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "archive_sound (Relation)        (None, 20)           640         movie[0][0]                      \n",
      "                                                                 person[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "cinematographer (Relation)      (None, 20)           640         movie[0][0]                      \n",
      "                                                                 person[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "composer (Relation)             (None, 20)           640         movie[0][0]                      \n",
      "                                                                 person[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "director (Relation)             (None, 20)           640         movie[0][0]                      \n",
      "                                                                 person[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "editor (Relation)               (None, 20)           640         movie[0][0]                      \n",
      "                                                                 person[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "producer (Relation)             (None, 20)           640         movie[0][0]                      \n",
      "                                                                 person[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "production_designer (Relation)  (None, 20)           640         movie[0][0]                      \n",
      "                                                                 person[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "writer (Relation)               (None, 20)           640         movie[0][0]                      \n",
      "                                                                 person[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "movie-out (Dense)               (None, 1)            11          movie[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "person-out (Dense)              (None, 1)            11          person[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "actor-out (Dense)               (None, 1)            21          actor[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "actress-out (Dense)             (None, 1)            21          actress[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "archive_footage-out (Dense)     (None, 1)            21          archive_footage[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "archive_sound-out (Dense)       (None, 1)            21          archive_sound[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cinematographer-out (Dense)     (None, 1)            21          cinematographer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "composer-out (Dense)            (None, 1)            21          composer[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "director-out (Dense)            (None, 1)            21          director[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "editor-out (Dense)              (None, 1)            21          editor[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "producer-out (Dense)            (None, 1)            21          producer[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "production_designer-out (Dense) (None, 1)            21          production_designer[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "writer-out (Dense)              (None, 1)            21          writer[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_embeding (Concatenate)      (None, 13)           0           movie-out[0][0]                  \n",
      "                                                                 person-out[0][0]                 \n",
      "                                                                 actor-out[0][0]                  \n",
      "                                                                 actress-out[0][0]                \n",
      "                                                                 archive_footage-out[0][0]        \n",
      "                                                                 archive_sound-out[0][0]          \n",
      "                                                                 cinematographer-out[0][0]        \n",
      "                                                                 composer-out[0][0]               \n",
      "                                                                 director-out[0][0]               \n",
      "                                                                 editor-out[0][0]                 \n",
      "                                                                 producer-out[0][0]               \n",
      "                                                                 production_designer-out[0][0]    \n",
      "                                                                 writer-out[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 5,350,873\n",
      "Trainable params: 5,350,873\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(vocabulary = dictionary, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = len(list(movies_map.keys()))\n",
    "lp = len(list(people_map.keys()))\n",
    "moviet = list(i for i in list(movies_map.keys()))\n",
    "random.shuffle(moviet)\n",
    "movietest = moviet[-lm//10:]\n",
    "moviet = moviet[:-lm//10]\n",
    "peoplet = list(i for i in list(people_map.keys()))\n",
    "random.shuffle(peoplet)\n",
    "peopletest = peoplet[-lp//10:]\n",
    "peoplet = peoplet[:-lp//10]\n",
    "relations = tuple(i for i in list(relations_map.keys()))\n",
    "out_map =  {i:n for n,i in enumerate(list(sorted(enties))+list(sorted(relations_map.keys())))}\n",
    "for i,j in relations_map.items():\n",
    "    random.shuffle(j)\n",
    "    relations_map[i]=j\n",
    "\n",
    "def sample_p(n):\n",
    "    return random.sample(peoplet, n),[[0,1]+[0 for i in range(len(out_map)-2)] for j in range(n)]\n",
    "\n",
    "def sample_m(n):\n",
    "    return random.sample(moviet, n),[[1]+[0 for i in range(len(out_map)-1)] for j in range(n)]\n",
    "    \n",
    "def sample_r(n):\n",
    "    s = []\n",
    "    res = []\n",
    "    for i in range(n):\n",
    "        s.append(random.choice(relations))\n",
    "        r = [1,1] + [0 for i in range(len(out_map)-2)]\n",
    "        r[out_map[s[i]]]=1\n",
    "        res.append(r)\n",
    "        ll = len(relations_map[s[-1]])\n",
    "        t1,t2 = random.choice(relations_map[s[-1]][:-ll//10])\n",
    "        s[-1] = ' '.join([s[-1],t1,t2])\n",
    "    return s,res\n",
    "\n",
    "def sample_pt(n):\n",
    "    return random.sample(peopletest, n),[[0,1]+[0 for i in range(len(out_map)-2)] for j in range(n)]\n",
    "\n",
    "def sample_mt(n):\n",
    "    return random.sample(movietest, n),[[1]+[0 for i in range(len(out_map)-1)] for j in range(n)]\n",
    "    \n",
    "def sample_rt(n):\n",
    "    s = []\n",
    "    res = []\n",
    "    for i in range(n):\n",
    "        s.append(random.choice(relations))\n",
    "        r = [1,1] + [0 for i in range(len(out_map)-2)]\n",
    "        r[out_map[s[i]]]=1\n",
    "        res.append(r)\n",
    "        ll = len(relations_map[s[-1]])\n",
    "        t1,t2 = random.choice(relations_map[s[-1]][-ll//10:])\n",
    "        s[-1] = ' '.join([s[-1],t1,t2])\n",
    "    return s,res\n",
    "\n",
    "def generate_p(batch_size=32,train=True):\n",
    "    while True:\n",
    "        data = []\n",
    "        datares = []\n",
    "        if train:\n",
    "            d,r = sample_p(batch_size)\n",
    "        else:\n",
    "            d,r = sample_pt(batch_size)\n",
    "        data+=d\n",
    "        datares+=r\n",
    "        inn = vect.transform(data)\n",
    "        yield inn.toarray(),np.array(datares)\n",
    "\n",
    "def generate_e(batch_size=32,train=True):\n",
    "    while True:\n",
    "        data = []\n",
    "        datares = []\n",
    "        samples_type = np.random.randint(2,size=batch_size)\n",
    "        samples_type.sort()\n",
    "        t1 = samples_type[samples_type==0]\n",
    "        if len(t1)!=0:\n",
    "            if train:\n",
    "                d,r = sample_m(len(t1))\n",
    "            else:\n",
    "                d,r = sample_mt(len(t1))\n",
    "            data+=d\n",
    "            datares+=r\n",
    "        t2 = samples_type[samples_type==1]\n",
    "        if len(t2)!=0:\n",
    "            if train:\n",
    "                d,r = sample_p(len(t2))\n",
    "            else:\n",
    "                d,r = sample_pt(len(t2))\n",
    "            data+=d\n",
    "            datares+=r\n",
    "        inn = vect.transform(data)\n",
    "        yield inn.toarray(),np.array(datares)\n",
    "        \n",
    "def generate_r(batch_size=32,train=True):\n",
    "    while True:\n",
    "        data = []\n",
    "        datares = []\n",
    "        if train:\n",
    "            d,r = sample_r(batch_size)\n",
    "        else:\n",
    "            d,r = sample_rt(batch_size)\n",
    "        data+=d\n",
    "        datares+=r\n",
    "        inn = vect.transform(data)\n",
    "        yield inn.toarray(),np.array(datares) \n",
    "\n",
    "\n",
    "def generate_mix(batch_size=32,train=True):\n",
    "    while True:\n",
    "        data = []\n",
    "        datares = []\n",
    "        samples_type = np.random.randint(3,size=batch_size)\n",
    "        samples_type.sort()\n",
    "        t1 = samples_type[samples_type==0]\n",
    "        if len(t1)!=0:\n",
    "            if train:\n",
    "                d,r = sample_m(len(t1))\n",
    "            else:\n",
    "                d,r = sample_mt(len(t1))\n",
    "            data+=d\n",
    "            datares+=r\n",
    "        t2 = samples_type[samples_type==1]\n",
    "        if len(t2)!=0:\n",
    "            if train:\n",
    "                d,r = sample_p(len(t2))\n",
    "            else:\n",
    "                d,r = sample_pt(len(t2))\n",
    "            data+=d\n",
    "            datares+=r\n",
    "        t3 = samples_type[samples_type==2]\n",
    "        if len(t3)!=0:\n",
    "            if train:\n",
    "                d,r = sample_r(len(t3))\n",
    "            else:\n",
    "                d,r = sample_rt(len(t3))\n",
    "            data+=d\n",
    "            datares+=r\n",
    "        inn = vect.transform(data)\n",
    "        yield inn.toarray(),np.array(datares) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 39s 393ms/step - loss: 0.2659 - acc: 0.9252 - val_loss: 0.1069 - val_acc: 0.9472\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 42s 421ms/step - loss: 0.0977 - acc: 0.9607 - val_loss: 0.0913 - val_acc: 0.9711\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 33s 331ms/step - loss: 0.0849 - acc: 0.9716 - val_loss: 0.0792 - val_acc: 0.9676\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 32s 317ms/step - loss: 0.0747 - acc: 0.9695 - val_loss: 0.0705 - val_acc: 0.9705\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 31s 309ms/step - loss: 0.0673 - acc: 0.9717 - val_loss: 0.0611 - val_acc: 0.9753\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 32s 317ms/step - loss: 0.0623 - acc: 0.9715 - val_loss: 0.0567 - val_acc: 0.9758\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 31s 314ms/step - loss: 0.0573 - acc: 0.9742 - val_loss: 0.0540 - val_acc: 0.9769\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 31s 309ms/step - loss: 0.0539 - acc: 0.9759 - val_loss: 0.0499 - val_acc: 0.9789\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 32s 324ms/step - loss: 0.0502 - acc: 0.9775 - val_loss: 0.0518 - val_acc: 0.9775\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 32s 324ms/step - loss: 0.0480 - acc: 0.9787 - val_loss: 0.0523 - val_acc: 0.9746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc4f4010b38>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train with entites\n",
    "model.fit_generator(generate_e(100), validation_data=generate_e(100,False), validation_steps=10, epochs=10, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODEL_NAME+'.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 0.9005 - acc: 0.8593 - val_loss: 0.3997 - val_acc: 0.8692\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 62s 617ms/step - loss: 0.2458 - acc: 0.9140 - val_loss: 0.1292 - val_acc: 0.9635\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 62s 619ms/step - loss: 0.0625 - acc: 0.9820 - val_loss: 0.0283 - val_acc: 0.9906\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 0.0126 - acc: 0.9962 - val_loss: 0.0044 - val_acc: 0.9995\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 0.0023 - acc: 0.9997 - val_loss: 0.0014 - val_acc: 0.9998\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 64s 641ms/step - loss: 6.9565e-04 - acc: 0.9999 - val_loss: 1.5837e-04 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 65s 645ms/step - loss: 2.3718e-04 - acc: 1.0000 - val_loss: 5.8466e-05 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 65s 651ms/step - loss: 1.4791e-04 - acc: 1.0000 - val_loss: 1.9913e-05 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 66s 656ms/step - loss: 4.2414e-04 - acc: 1.0000 - val_loss: 8.2723e-06 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 67s 672ms/step - loss: 1.6583e-06 - acc: 1.0000 - val_loss: 9.8791e-06 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc4f32d4ac8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train with relations\n",
    "model.fit_generator(generate_r(100), validation_data=generate_r(100,False), validation_steps=10, epochs=10, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODEL_NAME+'.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 46s 463ms/step - loss: 0.2711 - acc: 0.9498 - val_loss: 0.2208 - val_acc: 0.9494\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 45s 449ms/step - loss: 0.1727 - acc: 0.9502 - val_loss: 0.1207 - val_acc: 0.9552\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 46s 456ms/step - loss: 0.0974 - acc: 0.9582 - val_loss: 0.0681 - val_acc: 0.9674\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 0.0543 - acc: 0.9726 - val_loss: 0.0401 - val_acc: 0.9820\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 47s 470ms/step - loss: 0.0363 - acc: 0.9829 - val_loss: 0.0358 - val_acc: 0.9843\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 46s 464ms/step - loss: 0.0304 - acc: 0.9866 - val_loss: 0.0332 - val_acc: 0.9855\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 46s 463ms/step - loss: 0.0303 - acc: 0.9883 - val_loss: 0.0295 - val_acc: 0.9880\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 46s 463ms/step - loss: 0.0284 - acc: 0.9900 - val_loss: 0.0316 - val_acc: 0.9885\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 46s 464ms/step - loss: 0.0282 - acc: 0.9899 - val_loss: 0.0265 - val_acc: 0.9891\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 47s 473ms/step - loss: 0.0269 - acc: 0.9903 - val_loss: 0.0303 - val_acc: 0.9869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc4f32d4c88>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train with mix data\n",
    "model.fit_generator(generate_mix(100), validation_data=generate_mix(100,False), validation_steps=10, epochs=10, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODEL_NAME+'.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
